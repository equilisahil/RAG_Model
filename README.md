# RAG_Model
ðŸ“š First RAG (Retrieval-Augmented Generation) Project . This project demonstrates a simple RAG pipeline using Chroma as the vector store. 
HuggingFace embeddings for document indexing, and Groq-hosted LLMs (like LLaMA 3) for fast and accurate question answering. It takes input documents, embeds them, stores them in a vector database, and retrieves relevant chunks to generate responses using an LLM.
